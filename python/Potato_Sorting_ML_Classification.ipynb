{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e48a20-71f9-4f12-9731-416398f20f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance as dist\n",
    "from imutils import perspective\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import serial\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e457dc25-f040-463f-bd1c-286c46850166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint(ptA, ptB):\n",
    "\treturn ((ptA[0] + ptB[0]) * 0.5, (ptA[1] + ptB[1]) * 0.5)\n",
    "\n",
    "def filter_by_color(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Filters objects by the blue color in the frame\"\"\"\n",
    "    # Converts the image from BGR color space to HSV\n",
    "    # load the image, convert it to grayscale, and blur it slightly\n",
    "    upper = np.array([179, 255, 255], dtype=\"uint8\")\n",
    "    lower = np.array([0, 0, 180], dtype=\"uint8\")\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #hsv[:, :, 2] = cv2.equalizeHist(hsv[:, :, 2])\n",
    "    # Filter by color\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    return mask\n",
    "\n",
    "def remove_noise(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Removes the image noise\"\"\"\n",
    "    # Applies binary thresholding\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((15, 15), np.uint8)  # Defines a 5x5 kernel\n",
    "    # Applies morphological transformation with operator \"opening\"\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    return opening\n",
    "\n",
    "def find_background_area(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Applies Dilation morphological filter\"\"\"\n",
    "    # sure background area\n",
    "    kernel = np.ones((40, 40), np.uint8)  # Defines a 3x3 kernel\n",
    "    sure_bg = cv2.dilate(img, kernel, iterations=2)\n",
    "    return sure_bg\n",
    "\n",
    "def find_foreground_area(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Finds foreground area\"\"\"\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(img, cv2.DIST_L2, 3)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.1* dist_transform.max(), 255, 0)\n",
    "    return sure_fg\n",
    "\n",
    "def find_contours(sure_bg: np.ndarray, sure_fg: np.ndarray, image: np.ndarray):\n",
    "    \"\"\"Finds the contour of each image object\"\"\"\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    # Marker labeling\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    # Adds one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "    # Maks the region of unknown with zero\n",
    "    markers[unknown == 255] = 0\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    return markers\n",
    "\n",
    "def filter_contours(img):\n",
    "    \"\"\"Filter the image contours\"\"\"\n",
    "    kernel = np.ones((5, 5), np.uint8)  # Defines a 2x2 kernel\n",
    "    # Applies morphological transformation with operator \"closing\"\n",
    "    closed = cv2.morphologyEx(\n",
    "        img.astype(np.uint8), cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    # Applies binary thresholding\n",
    "    _, thresh = cv2.threshold(closed, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    # Finds the contours\n",
    "    contours, hierarchy = cv2.findContours(\n",
    "        thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE\n",
    "    )\n",
    "    contours_int = [\n",
    "        contours[i] for i in range(len(contours)) if hierarchy[0][i][2] < 0\n",
    "    ]\n",
    "    return contours_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "686381a8-abae-43b2-a029-571dd0b1c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the camera and its resolution\n",
    "cam = cv2.VideoCapture(1, cv2.CAP_DSHOW) #0=front-cam, 1=back-cam\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "#Set the scale value\n",
    "pixelsPerMetric = 71.52575404\n",
    "\n",
    "#Open the serial port connection\n",
    "serialcomm = serial.Serial('COM13', 9600)\n",
    "serialcomm.timeout = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ce4b6-4423-4b51-bd48-4272baeb4118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of Test\n",
      "\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Set the initial values for the loop\n",
    "potato = 1\n",
    "potato_size_l = []\n",
    "potatos_sizes_l = []\n",
    "frame_count = 1\n",
    "run_n = 1\n",
    "switch_servo = True\n",
    "\n",
    "#Create a while loop to capture the video from the camera\n",
    "while True:\n",
    "    \n",
    "    #read the camera frames\n",
    "    success, frame = cam.read()\n",
    "     \n",
    "    #if first frame was sucessfully captured - send the serial signal for Arduino to start belt    \n",
    "    if(success and frame_count == 1):\n",
    "        time.sleep(3)\n",
    "        print(serialcomm.readline().decode('ascii'))\n",
    "        serialcomm.write('Start'.encode())\n",
    "        print(serialcomm.readline().decode('ascii'))\n",
    "    \n",
    "    #Crop image to remove the sides of the converyor\n",
    "    cropped = frame[:,200:1000]\n",
    "    #Threshold the HSV\n",
    "    img = filter_by_color(cropped)\n",
    "    \n",
    "    #Noise removal and fitlering\n",
    "    img = remove_noise(img)\n",
    "    sure_bg = find_background_area(img)\n",
    "    sure_fg = find_foreground_area(img)\n",
    "    \n",
    "    #Obtains the contours\n",
    "    img = find_contours(sure_bg,sure_fg, image= cropped)\n",
    "    cnts = filter_contours(img = img)\n",
    "    \n",
    "    #Evaluate if they are within the limtis\n",
    "    has_valid_countour = [cv2.contourArea(c)>20000 or cv2.contourArea(c)>288000 for c in cnts]\n",
    "    \n",
    "    #If they are go to loop to measure potatoes\n",
    "    if any(has_valid_countour):\n",
    "        for c in cnts:\n",
    "             # if the contour is not sufficiently large, ignore it\n",
    "            area = cv2.contourArea(c)\n",
    "            #print(area)\n",
    "            if area < 20000 or area > 288000:\n",
    "                continue\n",
    "            \n",
    "            #compute the centroid from the countour \n",
    "            M = cv2.moments(c)\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "            \n",
    "            #If it is the first time running this section difference is 0\n",
    "            if(run_n == 1):\n",
    "                diff_cy = 0\n",
    "                \n",
    "            #otherwise uses the previous center\n",
    "            else: \n",
    "                diff_cy =  cY_past - cY\n",
    "            #print(diff_cy)\n",
    "            \n",
    "            #Saves the Y centroid coordinate for the next interaction\n",
    "            cY_past = cY\n",
    "            \n",
    "            # compute the rotated bounding box of the contour\n",
    "            box = cv2.minAreaRect(c)\n",
    "            box = cv2.cv.BoxPoints(box) if imutils.is_cv2() else cv2.boxPoints(box)\n",
    "            box = np.array(box, dtype=\"int\")\n",
    "            # order the points in the contour such that they appear\n",
    "            # in top-left, top-right, bottom-right, and bottom-left\n",
    "            # order, then draw the outline of the rotated bounding\n",
    "            # box\n",
    "            box = perspective.order_points(box)\n",
    "            cv2.drawContours(cropped, [box.astype(\"int\")], -1, (0, 255, 0), 2)\n",
    "            # loop over the original points and draw them\n",
    "            for (x, y) in box:\n",
    "                cv2.circle(cropped, (int(x), int(y)), 5, (0, 0, 255), -1)\n",
    "\n",
    "            # unpack the ordered bounding box, then compute the midpoint\n",
    "            # between the top-left and top-right coordinates, followed by\n",
    "            # the midpoint between bottom-left and bottom-right coordinates\n",
    "            (tl, tr, br, bl) = box\n",
    "            (tltrX, tltrY) = midpoint(tl, tr)\n",
    "            (blbrX, blbrY) = midpoint(bl, br)\n",
    "            # compute the midpoint between the top-left and top-right points,\n",
    "            # followed by the midpoint between the top-righ and bottom-right\n",
    "            (tlblX, tlblY) = midpoint(tl, bl)\n",
    "            (trbrX, trbrY) = midpoint(tr, br)\n",
    "\n",
    "            if cY > 200 and cY < 500:\n",
    "                # draw the midpoints on the image\n",
    "                cv2.circle(cropped, (int(tltrX), int(tltrY)), 5, (255, 0, 0), -1)\n",
    "                cv2.circle(cropped, (int(blbrX), int(blbrY)), 5, (255, 0, 0), -1)\n",
    "                cv2.circle(cropped, (int(tlblX), int(tlblY)), 5, (255, 0, 0), -1)\n",
    "                cv2.circle(cropped, (int(trbrX), int(trbrY)), 5, (255, 0, 0), -1)\n",
    "                # draw lines between the midpoints\n",
    "                cv2.line(cropped, (int(tltrX), int(tltrY)), (int(blbrX), int(blbrY)),\n",
    "                    (255, 0, 255), 2)\n",
    "                cv2.line(cropped, (int(tlblX), int(tlblY)), (int(trbrX), int(trbrY)),\n",
    "                    (255, 0, 255), 2)\n",
    "\n",
    "                # compute the Euclidean distance between the midpoints\n",
    "                dA = dist.euclidean((tltrX, tltrY), (blbrX, blbrY))\n",
    "                dB = dist.euclidean((tlblX, tlblY), (trbrX, trbrY))\n",
    "                # if the pixels per metric has not been initialized, then\n",
    "                # compute it as the ratio of pixels to supplied metric\n",
    "                # (in this case, inches)\n",
    "                if pixelsPerMetric is None:\n",
    "                    pixelsPerMetric = dB / 1\n",
    "\n",
    "                # compute the size of the object\n",
    "                dimA = dA / pixelsPerMetric\n",
    "                dimB = dB / pixelsPerMetric\n",
    "                # draw the object sizes on the image\n",
    "                cv2.putText(cropped, \"{:.1f}cm\".format(dimA),\n",
    "                    (int(tltrX - 15), int(tltrY - 10)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.65, (255, 255, 255), 2)\n",
    "                cv2.putText(cropped, \"{:.1f}cm\".format(dimB),\n",
    "                    (int(trbrX + 10), int(trbrY)), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.65, (255, 255, 255), 2)\n",
    "                potato_size_l.append([dimA, dimB])\n",
    "            else:\n",
    "                #If potato passed the 200 pixel line get all the data collected, take median and classify\n",
    "                if(cY - 200)< 0 and switch_servo:\n",
    "                    potato_size = np.median(potato_size_l, axis=0)\n",
    "                    potato_area = round(potato_size[0]*potato_size[1],2)\n",
    "                    \n",
    "                    #Classification is done per area in cm2\n",
    "                    if potato_area > 58:\n",
    "                        potato_class = 4\n",
    "                    if potato_area> 45 and potato_area <=58:\n",
    "                        potato_class = 3\n",
    "                    if potato_area> 35 and potato_area <=45:\n",
    "                        potato_class = 2\n",
    "                    if potato_area <=34:\n",
    "                        potato_class = 1\n",
    "                    \n",
    "                    #Save results in a list\n",
    "                    potatos_sizes_l.append([potato, round(potato_size[0], 2), round(potato_size[1],2), potato_area, potato_class])\n",
    "                    \n",
    "                    #Write the class on the serial port\n",
    "                    serialcomm.write(f'{potato_class}'.encode())\n",
    "                    #time.sleep(0.5)\n",
    "                    #print(serialcomm.readline().decode('ascii'))\n",
    "                    switch_servo = False\n",
    "                    print(potato)\n",
    "                \n",
    "                #Once the differnece is negative it got a new potato! Start everything again\n",
    "                if(diff_cy<-600):\n",
    "                    potato += 1\n",
    "                    potato_size_l = []\n",
    "                    switch_servo = True\n",
    "                    \n",
    "            run_n +=1\n",
    "    \n",
    "    #Save all the frame for analysis\n",
    "    cv2.imwrite(f\"frames_potato_sorter_5/frame{str(frame_count)}.jpg\", cropped)\n",
    "    cv2.imshow('potato_detection', cropped)\n",
    "    frame_count += 1\n",
    "    \n",
    "    #For a good system, a STOP button has to be implemented. In our case it is the keyboard letter \"q\"\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "#Once out of the loop close all open connections!\n",
    "cam.release()\n",
    "cv2.destroyWindow('potato_detection')\n",
    "serialcomm.write('Stop'.encode())\n",
    "print(serialcomm.readline().decode('ascii'))\n",
    "serialcomm.close()\n",
    "\n",
    "# And save the data collected\n",
    "results = pd.DataFrame(potatos_sizes_l)\n",
    "results.columns = ['Potato', 'Dimension1', 'Dimension2', 'Area', 'Classification']\n",
    "results.to_csv('seed_potato.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ebf7ebb-0a17-4c0c-a6ce-fe26f9e0746b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Potato</th>\n",
       "      <th>Dimension1</th>\n",
       "      <th>Dimension2</th>\n",
       "      <th>Area</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.31</td>\n",
       "      <td>36.54</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>6.30</td>\n",
       "      <td>36.66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5.94</td>\n",
       "      <td>6.36</td>\n",
       "      <td>37.82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5.89</td>\n",
       "      <td>6.28</td>\n",
       "      <td>36.99</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.36</td>\n",
       "      <td>36.91</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Potato  Dimension1  Dimension2   Area  Classification\n",
       "0       1        5.80        6.31  36.54               2\n",
       "1       2        5.82        6.30  36.66               2\n",
       "2       3        5.94        6.36  37.82               2\n",
       "3       4        5.89        6.28  36.99               2\n",
       "4       5        5.80        6.36  36.91               2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d283c81-50fc-4b78-b7b4-16382438a35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serialcomm.write('1'.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923aa627-5c3e-487e-9176-0e9455d88d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
